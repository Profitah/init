'use client';

import { useRef, useEffect, useState } from 'react';
import YouTube from 'react-youtube';

/* ---------- íƒ€ì… ---------- */
interface PitchPoint  { time_sec: number; pitch_hz: number; }
interface CaptionLine { startTime: number; endTime: number; script: string; }

export default function AudioPitchWithCaptionSVG() {
  const svgRef      = useRef<SVGSVGElement>(null);
  const playRef     = useRef<any>(null);

  // ë§ˆì´í¬ ìº¡ì²˜ refs
  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const bufRef      = useRef<Float32Array | null>(null);

  // íƒ€ì´ë° refs
  const startRef    = useRef(0);
  const lastIdxRef  = useRef(-1);
  const rafRef      = useRef(0);

  // ìº¡ì…˜ ì¸ë±ìŠ¤
  const curIdxRef   = useRef<number>(-1);

  /* ---------- ë°ì´í„° refs ---------- */
  const userPtsRef  = useRef<number[]>([]);

  /* ---------- state ---------- */
  const [defPts,  setDefPts]  = useState<PitchPoint[]>([]);
  const [caps,    setCaps]    = useState<CaptionLine[]>([]);
  const [curCap,  setCurCap]  = useState<CaptionLine | null>(null);

  /* ---------- constants ---------- */
  const W = 800, H = 220;
  const viewBox = `0 0 ${W} ${H}`;
  const VIDEO_ID = '-6bdHjc2gWM';

  /* ---------- JSON ë¡œë“œ ---------- */
  useEffect(() => {
    (async () => {
      const [pRes, cRes] = await Promise.all([
        fetch('/pitch.json'),
        fetch('/script.json'),
      ]);
      if (pRes.ok && cRes.ok) {
        setDefPts(await pRes.json());
        setCaps(await cRes.json());
      }
    })();
  }, []);

  /* ---------- frameDur ê³„ì‚° ---------- */
  const frameDurRef = useRef(0);
  const invFrameDur = useRef(0);
  useEffect(() => {
    if (defPts.length > 1) {
      const d = defPts[1].time_sec - defPts[0].time_sec;
      frameDurRef.current = d;
      invFrameDur.current = 1 / d;
    }
  }, [defPts]);

  /* ---------- autoCorrelate ---------- */
  function autoCorrelate(buf: Float32Array, sr: number) {
    const N = buf.length;
    let best = -1, bestCorr = 0;
    const rms = Math.sqrt(buf.reduce((s, v) => s + v*v, 0) / N);
    if (rms < 0.01) return -1;
    for (let off = 64; off < N/2; off++) {
      let corr = 0;
      for (let i = 0; i < N-off; i++) corr += buf[i]*buf[i+off];
      if (corr > bestCorr) { bestCorr = corr; best = off; }
    }
    return best > 0 ? sr / best : -1;
  }

  /* ---------- tickAudio (í´ë¡œì €) ---------- */
  const tickAudio = () => {
    const ctx = audioCtxRef.current!;
    const analyser = analyserRef.current!;
    const buf = bufRef.current!;

    const now = ctx.currentTime - startRef.current;

    // ìº¡ì…˜ ë™ê¸°í™”
    const capIdx = caps.findIndex(c => now >= c.startTime && now <= c.endTime);
    if (capIdx !== curIdxRef.current) {
      curIdxRef.current = capIdx;
      setCurCap(capIdx >= 0 ? caps[capIdx] : null);

      // ìƒˆ êµ¬ê°„ ì‹œì‘ â†’ ì´ì „ ë°ì´í„° ì „ë¶€ ì‚­ì œ
      userPtsRef.current = [];
      lastIdxRef.current = -1;
    }

    // ì‚¬ìš©ì í”¼ì¹˜ ìˆ˜ì§‘ & ìœˆë„ìš°ì— ì¶”ê°€
    analyser.getFloatTimeDomainData(buf);
    const p = autoCorrelate(buf, ctx.sampleRate);
    userPtsRef.current.push(p > 0 ? p : 0);
    // ìµœê·¼ 1000í”„ë ˆì„ë§Œ ìœ ì§€
    if (userPtsRef.current.length > 1000) {
      userPtsRef.current.shift();
    }

    // SVG polyline ì—…ë°ì´íŠ¸
    const segStart = curCap?.startTime ?? 0;
    const nextStart = caps[curIdxRef.current + 1]?.startTime;
    const segEnd = nextStart ?? curCap?.endTime ?? 1;
    const defSeg = defPts.filter(p => p.time_sec >= segStart && p.time_sec <= segEnd);
    const maxPitch = Math.max(...defSeg.map(p=>p.pitch_hz), ...userPtsRef.current, 1);

    const userLine = svgRef.current!.querySelector<SVGPolylineElement>('.user-line');
    if (userLine) {
      const pts = buildLine(userPtsRef.current, true, segStart, segEnd, maxPitch);
      userLine.setAttribute('points', pts);
    }

    rafRef.current = requestAnimationFrame(tickAudio);
  };

  /* ---------- ì‹œì‘/ì¬ì‹œì‘ ---------- */
  const startAll = async () => {
    playRef.current?.playVideo?.();

    if (audioCtxRef.current) {
      if (audioCtxRef.current.state === 'suspended') {
        await audioCtxRef.current.resume();
        rafRef.current = requestAnimationFrame(tickAudio);
      }
      return;
    }

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const ctx = new AudioContext();
    if (ctx.state === 'suspended') await ctx.resume();

    const analyser = ctx.createAnalyser();
    analyser.fftSize = 2048;
    analyser.smoothingTimeConstant = 0.2;
    const buf = new Float32Array(analyser.fftSize);

    ctx.createMediaStreamSource(stream).connect(analyser);

    audioCtxRef.current = ctx;
    analyserRef.current = analyser;
    bufRef.current      = buf;
    startRef.current    = ctx.currentTime;
    userPtsRef.current  = [];

    rafRef.current = requestAnimationFrame(tickAudio);
  };

  /* ---------- ì¤‘ì§€ = ì¼ì‹œì •ì§€ ---------- */
  const stopAll = async () => {
    playRef.current?.pauseVideo?.();
    if (!audioCtxRef.current) return;
    cancelAnimationFrame(rafRef.current);
    await audioCtxRef.current.suspend();
  };

  /* ---------- YouTube ì¤€ë¹„ ---------- */
  const onPlayerReady = (e: any) => {
    playRef.current = e.target;
  };

  /* ---------- polyline ìƒì„± í•¨ìˆ˜ ---------- */
  function buildLine(
    src: (PitchPoint|number)[],
    isUser: boolean,
    sStart: number,
    sEnd: number,
    maxP: number
  ) {
    const dur = Math.max(sEnd - sStart, 0.01);
    return src.map((v,i) => {
      const pitch = isUser ? (v as number) : (v as PitchPoint).pitch_hz;
      const t = isUser
        ? sStart + i * frameDurRef.current
        : (v as PitchPoint).time_sec;
      const x = ((t - sStart)/dur) * W;
      const y = H - Math.min(pitch/maxP,1) * H;
      return `${x},${y}`;
    }).join(' ');
  }

  /* ---------- ë Œë”ë§ ---------- */
  return (
    <div style={{ padding:'2rem', textAlign:'center', color:'#fff' }}>
      <h2>ğŸ™ï¸ ëŒ€ì‚¬Â·ì¹¨ë¬µ êµ¬ê°„ë³„ ì‹¤ì‹œê°„ í”¼ì¹˜</h2>
      <YouTube
        videoId={VIDEO_ID}
        onReady={onPlayerReady}
        opts={{ playerVars:{ playsinline:1, controls:1 } }}
      />
      <svg
        ref={svgRef}
        viewBox={viewBox}
        style={{
          width:'100%', maxWidth:W,
          background:'#111', border:'1px solid #444', borderRadius:4
        }}
      >
        {/* ê¸°ì¤€ í”¼ì¹˜ (íŒŒë‘) */}
        {defPts.length > 1 && curCap && (
          <polyline
            points={buildLine(
              defPts.filter(p => p.time_sec >= curCap.startTime && p.time_sec <= (caps[curIdxRef.current+1]?.startTime ?? curCap.endTime)),
              false,
              curCap.startTime,
              (caps[curIdxRef.current+1]?.startTime ?? curCap.endTime),
              Math.max(1, ...defPts.map(p=>p.pitch_hz))
            )}
            fill="none"
            stroke="deepskyblue"
            strokeWidth={2}
          />
        )}
        {/* ì‚¬ìš©ì í”¼ì¹˜ (ë¹¨ê°•) */}
        <polyline
          className="user-line"
          fill="none"
          stroke="tomato"
          strokeWidth={2}
          points=""
        />
      </svg>
      <div style={{
        marginTop:'1rem', minHeight:'2.2em',
        fontSize:'1.1rem', color:'#0f0'
      }}>
        {curCap?.script ?? ''}
      </div>
      <div style={{ marginTop:'1rem' }}>
        <button onClick={startAll} style={{ marginRight:'1rem' }}>ì‹œì‘</button>
        <button onClick={stopAll}>ì¤‘ì§€</button>
      </div>
    </div>
  );
}
