'use client';

import { useRef, useEffect, useState } from 'react';
import YouTube, { YouTubeEvent } from 'react-youtube';

/* ---------- íƒ€ì… ---------- */
interface PitchPoint  { time_sec: number; pitch_hz: number; }
interface CaptionLine { startTime: number; endTime: number; script: string; }

export default function AudioPitchWithCaptionSVG() {
  const svgRef      = useRef<SVGSVGElement>(null);
  const playRef     = useRef<any>(null);

  // ë§ˆì´í¬ ìº¡ì²˜ refs
  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const bufRef      = useRef<Float32Array | null>(null);

  // íƒ€ì´ë° refs
  const startRef    = useRef(0);
  const rafRef      = useRef(0);

  // ìº¡ì…˜ ì¸ë±ìŠ¤
  const curIdxRef   = useRef<number>(-1);

  /* ---------- state ---------- */
  const [defPts,  setDefPts]  = useState<PitchPoint[]>([]);
  const [caps,    setCaps]    = useState<CaptionLine[]>([]);
  const [curCap,  setCurCap]  = useState<CaptionLine | null>(null);
  const [userPts, setUserPts] = useState<number[]>([]);
  const [ended,   setEnded]   = useState(false);

  /* ---------- constants ---------- */
  const W = 800, H = 220;
  const viewBox = `0 0 ${W} ${H}`;
  const VIDEO_ID = '-6bdHjc2gWM';

  /* ---------- JSON ë¡œë“œ ---------- */
  useEffect(() => {
    (async () => {
      const [pRes, cRes] = await Promise.all([
        fetch('/pitch.json'),
        fetch('/script.json'),
      ]);
      if (pRes.ok && cRes.ok) {
        setDefPts(await pRes.json());
        setCaps(await cRes.json());
      }
    })();
  }, []);

  /* ---------- frameDur ê³„ì‚° ---------- */
  const frameDurRef = useRef(0);
  const invFrameDur = useRef(0);
  useEffect(() => {
    if (defPts.length > 1) {
      const d = defPts[1].time_sec - defPts[0].time_sec;
      frameDurRef.current = d;
      invFrameDur.current = 1 / d;
    }
  }, [defPts]);

  /* ---------- autoCorrelate ---------- */
  function autoCorrelate(buf: Float32Array, sr: number) {
    const N = buf.length;
    let best = -1, bestCorr = 0;
    const rms = Math.sqrt(buf.reduce((s, v) => s + v*v, 0) / N);
    if (rms < 0.01) return -1;
    for (let off = 64; off < N/2; off++) {
      let corr = 0;
      for (let i = 0; i < N-off; i++) corr += buf[i]*buf[i+off];
      if (corr > bestCorr) { bestCorr = corr; best = off; }
    }
    return best > 0 ? sr / best : -1;
  }

  /* ---------- tickAudio ---------- */
  const tickAudio = () => {
    const ctx = audioCtxRef.current!;
    const analyser = analyserRef.current!;
    const buf = bufRef.current!;

    const now = ctx.currentTime - startRef.current;

    // ìº¡ì…˜ ë™ê¸°í™”
    const capIdx = caps.findIndex(c => now >= c.startTime && now <= c.endTime);
    if (capIdx !== curIdxRef.current) {
      curIdxRef.current = capIdx;
      setCurCap(capIdx >= 0 ? caps[capIdx] : null);
      setUserPts([]);             // êµ¬ê°„ ë°”ë€” ë•Œ ì´ˆê¸°í™”
    }

    // ì‚¬ìš©ì í”¼ì¹˜ ìˆ˜ì§‘
    analyser.getFloatTimeDomainData(buf);
    const p = autoCorrelate(buf, ctx.sampleRate);
    setUserPts(u => {
      const next = [...u, p > 0 ? p : 0];
      return next.length > 1000 ? next.slice(-1000) : next;
    });

    rafRef.current = requestAnimationFrame(tickAudio);
  };

  /* ---------- ë§ˆì´í¬ ì‹œì‘/ì¬ê°œ ---------- */
  const startMic = async () => {
    if (ended) return;
    if (audioCtxRef.current) {
      if (audioCtxRef.current.state === 'suspended') {
        await audioCtxRef.current.resume();
        rafRef.current = requestAnimationFrame(tickAudio);
      }
      return;
    }
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const ctx = new AudioContext();
    if (ctx.state === 'suspended') await ctx.resume();

    const analyser = ctx.createAnalyser();
    analyser.fftSize = 2048;
    analyser.smoothingTimeConstant = 0.2;
    const buf = new Float32Array(analyser.fftSize);

    ctx.createMediaStreamSource(stream).connect(analyser);
    audioCtxRef.current = ctx;
    analyserRef.current = analyser;
    bufRef.current      = buf;
    startRef.current    = ctx.currentTime;
    setUserPts([]);

    rafRef.current = requestAnimationFrame(tickAudio);
  };

  /* ---------- ë§ˆì´í¬ ì¼ì‹œì •ì§€ ---------- */
  const stopMic = async () => {
    if (!audioCtxRef.current) return;
    cancelAnimationFrame(rafRef.current);
    await audioCtxRef.current.suspend();
  };

  /* ---------- ì˜ìƒ ì¬ìƒ/ì¼ì‹œì •ì§€/ì¢…ë£Œ ë™ê¸°í™” ---------- */
  const onPlayerStateChange = (e: YouTubeEvent) => {
    if (e.data === 1) {         // playing
      startMic();
    } else if (e.data === 2) {  // paused
      stopMic();
    } else if (e.data === 0) {  // ended
      setEnded(true);
      stopMic();
    }
  };

  /* ---------- YouTube ì¤€ë¹„ ---------- */
  const onPlayerReady = (e: any) => {
    playRef.current = e.target;
  };

  /* ---------- polyline ìƒì„± ---------- */
  function buildLine(
    src: (PitchPoint|number)[],
    isUser: boolean,
    sStart: number,
    sEnd: number,
    maxP: number
  ) {
    const dur = Math.max(sEnd - sStart, 0.01);
    return src.map((v,i) => {
      const pitch = isUser ? (v as number) : (v as PitchPoint).pitch_hz;
      const t = isUser
        ? sStart + i * frameDurRef.current
        : (v as PitchPoint).time_sec;
      const x = ((t - sStart)/dur)*W;
      const y = H - Math.min(pitch/maxP,1)*H;
      return `${x},${y}`;
    }).join(' ');
  }

  /* ---------- ë Œë”ë§ ---------- */
  const segStart = curCap?.startTime ?? 0;
  const nextStart = caps[curIdxRef.current + 1]?.startTime;
  const segEnd = nextStart ?? curCap?.endTime ?? 1;
  const defSeg = defPts.filter(p => p.time_sec >= segStart && p.time_sec <= segEnd);
  const maxPitch = Math.max(...defSeg.map(p=>p.pitch_hz), ...userPts, 1);

  return (
    <div style={{ padding:'2rem', textAlign:'center', color:'#fff' }}>
      <h2>ğŸ™ï¸ ëŒ€ì‚¬Â·ì¹¨ë¬µ êµ¬ê°„ë³„ ì‹¤ì‹œê°„ í”¼ì¹˜</h2>
      <YouTube
        videoId={VIDEO_ID}
        onReady={onPlayerReady}
        onStateChange={onPlayerStateChange}
        opts={{ playerVars:{ playsinline:1, controls:1 } }}
      />
      <svg
        ref={svgRef}
        viewBox={viewBox}
        style={{
          width:'100%', maxWidth:W,
          background:'#111', border:'1px solid #444', borderRadius:4
        }}
      >
        {/* ê¸°ì¤€ í”¼ì¹˜ (íŒŒë‘) */}
        {defSeg.length > 1 && (
          <polyline
            points={buildLine(defSeg,false,segStart,segEnd,maxPitch)}
            fill="none"
            stroke="deepskyblue"
            strokeWidth={2}
          />
        )}
        {/* ì‚¬ìš©ì í”¼ì¹˜ (ë¹¨ê°•) */}
        <polyline
          points={buildLine(userPts,true,segStart,segEnd,maxPitch)}
          fill="none"
          stroke="tomato"
          strokeWidth={2}
        />
      </svg>
      <div style={{
        marginTop:'1rem', minHeight:'2.2em',
        fontSize:'1.1rem', color:'#0f0'
      }}>
        {curCap?.script ?? ''}
      </div>
      <div style={{ marginTop:'1rem' }}>
        <button onClick={() => playRef.current.playVideo()} style={{ marginRight:'1rem' }} disabled={ended}>
          ì¬ìƒ
        </button>
        <button onClick={() => playRef.current.pauseVideo()} disabled={ended}>
          ì¼ì‹œì •ì§€
        </button>
      </div>
    </div>
  );
}
